mindmap
  root((大模型评测体系))
    目的
      了解模型能力
      问题诊断
      模型选型
      迭代优化
      效果展示
    方向
      基础能力
        语言理解
        语言生成
        推理能力
        知识记忆
      专业能力
        代码能力
        数学能力
        医学知识
        法律知识
        金融知识
      安全与伦理
        有害内容识别
        偏见检测
        隐私保护
      效率与成本
        推理速度
        资源消耗
    范围
      模型层面
        单模型评测
        多模型对比评测
      场景层面
        通用场景评测
        特定领域场景评测
      全面性
        全面评测
        针对性评测
    评测数据集
      公开数据集
        通用 benchmark (GLUE, SuperGLUE)
        特定领域数据集 (MMLU, C-Eval)
      自建数据集
        领域特定数据集
        用户行为数据
      数据集类型
        分类数据集
        问答数据集
        生成数据集
        对话数据集
    评测大模型
      通用大模型
        GPT系列
        LLAMA系列
        国内通用大模型 (文心一言, 通义千问, 百川)
      垂直领域大模型
        医疗大模型
        金融大模型
        法律大模型
      开源 vs. 闭源
        开源模型评测
        闭源模型评测
    评测指标
      准确率
        分类准确率
        问答准确率
      精确率/召回率/F1
        信息检索
        关系抽取
      BLEU/ROUGE/METEOR/困惑度
        文本生成
        机器翻译
      人工评估
        流畅度
        相关性
        连贯性
        信息量
        帮助性
    分数计算方式
      指标加权平均
      简单平均
      排名
      综合评分
    环境准备
      硬件环境
        GPU/CPU 资源
        内存需求
        存储空间
      软件环境
        操作系统
        Python 环境
        深度学习框架 (PyTorch, TensorFlow)
        评测工具库
      网络环境
        数据下载
        模型访问
    评测执行
      自动化评测脚本
      人工评测流程
      评测流程管理
      版本控制
    异常情况处理
      数据异常
        数据缺失
        数据格式错误
      模型异常
        模型崩溃
        输出异常
      环境异常
        网络中断
        硬件故障
      异常记录与报告
    评测分析
      结果统计分析
      对比分析 (模型之间)
      趋势分析 (迭代版本)
      错误分析 (case study)
      性能瓶颈分析
    结果展示
      评测报告
        详细报告
        简要报告
      可视化图表
        性能指标图表
        对比图表
      在线评测平台
      API 接口
